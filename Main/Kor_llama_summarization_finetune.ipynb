{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 1. 허깅페이스를 통한 한국어 말뭉치 데이터가 학습된, Llama 3.1 8b를 가져오기. (from :Bllossom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "import trl\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "2.6.0+cu124\n",
      "12.4\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"  #gpu 확인을 위해 사용\n",
    "print(device)\n",
    "print(torch.__version__)  # PyTorch 버전 확인\n",
    "print(torch.version.cuda)  # PyTorch가 사용하는 CUDA 버전 확인\n",
    "print(torch.cuda.is_available())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'Bllossom/llama-3.2-Korean-Bllossom-3B'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "### https://huggingface.co/Bllossom/llama-3.2-Korean-Bllossom-3B 참조.\n",
    "model=  AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cuda\",\n",
    ")\n",
    "\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = tokenizer.apply_chat_template(\n",
    "#     messages,\n",
    "#     add_generation_prompt=True,\n",
    "#     return_tensors=\"pt\"\n",
    "# ).to(model.device)\n",
    "\n",
    "\n",
    "# 허깅페이스 카드에 나와있는 것은 챗 탬플릿이다. 다만 프롬프트를 세부적으로 작성하기 위해 프롬프트를 아래와 같이 직접 작성하고자 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\news_tts_project\\Lib\\site-packages\\accelerate\\utils\\modeling.py:1536: UserWarning: Current model requires 128 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.45it/s]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "철수가 20개의 연필을 가지고 있었고 영희가 절반을 가져갔을 때, 철수는 20 / 2 = 10개의 연필을 가지고 있습니다.\n",
      "\n",
      "그리고 민수가 남은 5개를 가져갔을 때, 철수에게 남은 연필의 갯수는 10 - 5 = 5개입니다.\n",
      "\n",
      "따라서 철수에게 남은 연필의 갯수는 5개입니다.\n"
     ]
    }
   ],
   "source": [
    "model_id = 'Bllossom/llama-3.2-Korean-Bllossom-3B'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "instruction = \"철수가 20개의 연필을 가지고 있었는데 영희가 절반을 가져가고 민수가 남은 5개를 가져갔으면 철수에게 남은 연필의 갯수는 몇개인가요?\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": f\"{instruction}\"}\n",
    "    ]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.convert_tokens_to_ids(\"<|end_of_text|>\"),\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=1024,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[128000, 128006,   9125, 128007,    271,  38766,   1303,  33025,   2696,\n",
      "             25,   6790,    220,   2366,     18,    198,  15724,   2696,     25,\n",
      "            220,   1544,  13806,    220,   2366,     20,    271,   2675,    527,\n",
      "            264,  11190,  15592,  18328,     13,   5321,   4320,    279,   1217,\n",
      "            596,   4860,  47626,     13, 113783,  34804, 101003,  67119,  24486,\n",
      "          15592, 101139,  30426,  25941,  95252,  29726, 119519,     13,  41820,\n",
      "         110257, 109760,  19954, 112107, 108280, 104834, 102893, 111964,  34983,\n",
      "          92769,     13, 128009, 128006,    882, 128007,    271, 107837, 123503,\n",
      "            220,    508, 123590,  78453, 110174,  18359, 120693, 107417, 103170,\n",
      "         101603, 105204,  20565, 110217, 101738,  18359,  89946,  20565,  35495,\n",
      "         107138, 123503, 102484,  34804,    220,     20, 117594,  89946,  14705,\n",
      "            242,  91040, 112521,  24140, 102244, 102484,  34804,  78453, 110174,\n",
      "          21028,  17196,    107,  24140,  16969, 113156,  60861, 115372,  36811,\n",
      "             30, 128009, 128006,  78191, 128007,    271]])\n"
     ]
    }
   ],
   "source": [
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "article =\"\"\"\n",
    "블랙핑크 멤버들의 솔로 작품이 연달아 좋은 반응을 얻고 있다. 블랙핑크는 2023년 YG엔터테인먼트와 팀 활동 재계약을 맺으면서 개인 활동은 각자 새로운 둥지를 찾거나 꾸려서 하기로 했다. 이후 리사, 로제, 제니가 선보인 작품은 하나같이 세계 정상급 자본력과 기획력이 결합해야 나올 수 있는 퀄리티로 화제를 모았다. 올해 블랙핑크 컴백이 예상되는 가운데 지수가 2월 14일 미니 앨범 ‘아모르타주(AMORTAGE)’를 발매함으로써 네 멤버 모두 각자의 작업물을 내놓게 됐다.\n",
    "‌타이틀곡 ‘어스퀘이크(earthquake)’는 듣다 보면 어쩐지 교묘하게 뒤엉킨 듯한 기분이 든다. 노래 각 부분이 서로 다른 방식으로 선명하게 인상을 남기기 때문이다. 호흡을 짚어가며 단음 위주로 흐르던 보컬이 “벗어나려 할수록…”으로 진입할 때면 갑자기 멜로디컬해지고, 심지어 1990년대 댄스가요 같은 인상마저 준다. “바우트 투 블로(Bout to blow)”라는 가사 그대로 터질 것만 같던 긴장이 시원하게 해소되는 건 후렴 부분부터다.\n",
    "블랙핑크의 또 다른 세계\n",
    "간단하되 오묘한 모티프로 음역을 옮겨가며 반복되는 후렴은 기하학적인 인상을 준다. 뜨거운 훅은 아니지만 선명하게 각인될 만하고, 무엇보다 안정감이 빼어나다. ‘이제 노래가 제자리로 돌아왔다’는 기분을 느끼게 한다. 거기에 시원하게 달려 나가는 클럽 스타일 하우스 비트가 결합한다. 기분은 ‘이제 춤출 일만 남았다’로 바뀐다. 마침 뮤직비디오 속 지수도 댄서들을 ‘거느리고’ 춤을 춘다. 이는 분명 팝 시장에서 하우스 음악이 제공할 수 있는 가장 좋은 점 가운데 하나다.\n",
    "‌뮤직비디오는 K팝의 정수를 가져와 멋들어지게 표현해낸다. 전체주의적인 사회에서 권력과 감성이 대결한다는 설정, 질주하는 슈퍼카, 화려한 군무 같은 것은 K팝을 대외적으로 대표하는 이미지라 할 만하다. 어둡고 위압적인 사무실 풍경이나 거대한 스마트폰 자판 위에서 춤추는 댄서들 모습 등을 보면 금붙이 하나 없이도 ‘부티’가 흐른다는 느낌이 든다. 그리고 “그를 믿어도 될까”라는 질문 앞에서 가소롭다는 듯한 웃음을 띠며 가속페달을 밟아버리는 지수의 모습이 전하는 쾌감도 보통이 아니다.\n",
    "‌이미 개인 작품을 선보인 다른 멤버들에 비해 지수의 노선은 좀 더 K팝적이다. K팝 정상에서 만들어낼 수 있는 것, 그러나 역시 블랙핑크 틀 안에서는 도무지 상상하기 어려운 어떤 것이다. 네 멤버의 네 방향 이정표가 이렇게 완성됐다. 이를 따라 확장될 새로운 블랙핑크의 세계를 기대하지 않기 어렵다.\n",
    "\"\"\"\n",
    "\n",
    "keyword =\"블랙핑크\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "요약 규칙:\n",
    "1. {keyword}가 포함된 내용 위주로 요약해주세요.\n",
    "2. {keyword}가 포함되지 않은 부분은 생략해주세요.\n",
    "3. 5문장 이상으로 요약해주세요.\n",
    "4. 같은 내용의 문장을 반복하지 마세요.\n",
    "5. 모르는 부분은 대답하지 마세요.\n",
    "6. 문장을 생성할 때 구어체로 이어지게 해주세요.\n",
    "\n",
    "다음 문장을 요약해주세요.: \\n\n",
    "{article} \\n\n",
    "\n",
    "요약:\n",
    "<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "input_ids= tokenizer(prompt,\n",
    "    return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.convert_tokens_to_ids(\"<|end_of_text|>\"),\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=1024,\n",
    "    do_sample=True,\n",
    "    temperature=0.5,\n",
    "    top_k=40,\n",
    "    top_p=0.95\n",
    ")\n",
    "\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "요약 규칙:\n",
      "1. 블랙핑크가 포함된 내용 위주로 요약해주세요.\n",
      "2. 블랙핑크가 포함되지 않은 부분은 생략해주세요.\n",
      "3. 5문장 이상으로 요약해주세요.\n",
      "4. 같은 내용의 문장을 반복하지 마세요.\n",
      "5. 모르는 부분은 대답하지 마세요.\n",
      "6. 문장을 생성할 때 구어체로 이어지게 해주세요.\n",
      "\n",
      "다음 문장을 요약해주세요.: \n",
      "\n",
      "\n",
      "블랙핑크 멤버들의 솔로 작품이 연달아 좋은 반응을 얻고 있다. 블랙핑크는 2023년 YG엔터테인먼트와 팀 활동 재계약을 맺으면서 개인 활동은 각자 새로운 둥지를 찾거나 꾸려서 하기로 했다. 이후 리사, 로제, 제니가 선보인 작품은 하나같이 세계 정상급 자본력과 기획력이 결합해야 나올 수 있는 퀄리티로 화제를 모았다. 올해 블랙핑크 컴백이 예상되는 가운데 지수가 2월 14일 미니 앨범 ‘아모르타주(AMORTAGE)’를 발매함으로써 네 멤버 모두 각자의 작업물을 내놓게 됐다.\n",
      "‌타이틀곡 ‘어스퀘이크(earthquake)’는 듣다 보면 어쩐지 교묘하게 뒤엉킨 듯한 기분이 든다. 노래 각 부분이 서로 다른 방식으로 선명하게 인상을 남기기 때문이다. 호흡을 짚어가며 단음 위주로 흐르던 보컬이 “벗어나려 할수록…”으로 진입할 때면 갑자기 멜로디컬해지고, 심지어 1990년대 댄스가요 같은 인상마저 준다. “바우트 투 블로(Bout to blow)”라는 가사 그대로 터질 것만 같던 긴장이 시원하게 해소되는 건 후렴 부분부터다.\n",
      "블랙핑크의 또 다른 세계\n",
      "간단하되 오묘한 모티프로 음역을 옮겨가며 반복되는 후렴은 기하학적인 인상을 준다. 뜨거운 훅은 아니지만 선명하게 각인될 만하고, 무엇보다 안정감이 빼어나다. ‘이제 노래가 제자리로 돌아왔다’는 기분을 느끼게 한다. 거기에 시원하게 달려 나가는 클럽 스타일 하우스 비트가 결합한다. 기분은 ‘이제 춤출 일만 남았다’로 바뀐다. 마침 뮤직비디오 속 지수도 댄서들을 ‘거느리고’ 춤을 춘다. 이는 분명 팝 시장에서 하우스 음악이 제공할 수 있는 가장 좋은 점 가운데 하나다.\n",
      "‌뮤직비디오는 K팝의 정수를 가져와 멋들어지게 표현해낸다. 전체주의적인 사회에서 권력과 감성이 대결한다는 설정, 질주하는 슈퍼카, 화려한 군무 같은 것은 K팝을 대외적으로 대표하는 이미지라 할 만하다. 어둡고 위압적인 사무실 풍경이나 거대한 스마트폰 자판 위에서 춤추는 댄서들 모습 등을 보면 금붙이 하나 없이도 ‘부티’가 흐른다는 느낌이 든다. 그리고 “그를 믿어도 될까”라는 질문 앞에서 가소롭다는 듯한 웃음을 띠며 가속페달을 밟아버리는 지수의 모습이 전하는 쾌감도 보통이 아니다.\n",
      "‌이미 개인 작품을 선보인 다른 멤버들에 비해 지수의 노선은 좀 더 K팝적이다. K팝 정상에서 만들어낼 수 있는 것, 그러나 역시 블랙핑크 틀 안에서는 도무지 상상하기 어려운 어떤 것이다. 네 멤버의 네 방향 이정표가 이렇게 완성됐다. 이를 따라 확장될 새로운 블랙핑크의 세계를 기대하지 않기 어렵다.\n",
      " \n",
      "\n",
      "\n",
      "요약:\n",
      "\n",
      "블랙핑크 멤버들은 각자 새로운 작업물을 내놓고 있다. 리사, 로제, 제니도 각각의 솔로 작품이 좋은 반응을 받고 있다. 지수는 2월 14일 미니 앨범 ‘아모르타주(AMORTAGE)’를 발매하며 네 멤버 모두가 각자의 작업물을 내놓게 됐다. 타이틀곡 ‘어스퀘이크(earthquake)’는 보컬과 멜로디가 서로 다른 방식으로 선명하게 인상을 남기며, 후렴 부분은 기하학적인 인상을 준다. 뮤직비디오는 K팝의 정수를 가져와 멋들어지게 표현하며, 지수의 노선은 K팝적이지만 블랙핑크 틀 안에서는 도무지 상상하기 어려운 것이다. 네 멤버의 네 방향 이정표가 완성돼 새로운 블랙핑크의 세계를 기대할 수 있다.\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original eos_token_id: 128009\n",
      "Original bos_token_id: 128000\n",
      "Using eos_id: 128009\n"
     ]
    }
   ],
   "source": [
    "print(\"Original eos_token_id:\", tokenizer.eos_token_id)\n",
    "print(\"Original bos_token_id:\", tokenizer.bos_token_id)\n",
    "\n",
    "eos_id = tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "print(\"Using eos_id:\", eos_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. summarize를 수행하기 위한 파인튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\news_tts_project\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub\\datasets--daekeun-ml--naver-news-summarization-ko. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split: 100%|██████████| 22194/22194 [00:00<00:00, 23768.46 examples/s]\n",
      "Generating validation split: 100%|██████████| 2466/2466 [00:00<00:00, 22878.58 examples/s]\n",
      "Generating test split: 100%|██████████| 2740/2740 [00:00<00:00, 23269.79 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 파인튜닝을 위한 데이터셋 \n",
    "data = load_dataset(\"daekeun-ml/naver-news-summarization-ko\") #네이버 뉴스 요약 데이터셋 : https://huggingface.co/datasets/daekeun-ml/naver-news-summarization-ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#파인튜닝을 위한 데이터 프롬프트 문 작성 함수.\n",
    "# def generate_prompts(example):\n",
    "#     prompt_list = []\n",
    "#     for i in range(len(example['document'])):\n",
    "#         prompt_list.append(\n",
    "# f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>다음 글을 요약해주세요:\n",
    "# {example['document'][i]}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "# {example['summary'][i]}<|eot_id|>\"\"\"\n",
    "#         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news_tts_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
